#!/usr/bin/env python3
"""
NotebookLM ä¸­æ–‡ Podcast è™•ç†å™¨ - ç¤ºç¯„è…³æœ¬
å°‡è‹±æ–‡ NotebookLM éŸ³é »è½‰æ›ç‚ºè‡ªç„¶çš„ä¸­æ–‡å°è©± Podcast

ä½¿ç”¨æ–¹æ³•:
python demo_processor.py [input_audio.wav]
"""

import os
import sys
import asyncio
from pathlib import Path
from audio_processor import AudioProcessor
from dotenv import load_dotenv

def create_sample_audio():
    """å‰µå»ºç¤ºç¯„éŸ³é »æ–‡ä»¶ï¼ˆå¦‚æœæ²’æœ‰è¼¸å…¥æ–‡ä»¶ï¼‰"""
    print("ğŸµ å‰µå»ºç¤ºç¯„éŸ³é »æ–‡ä»¶...")
    
    # å‰µå»ºä¸€å€‹ç°¡å–®çš„ç¤ºç¯„éŸ³é »ï¼ˆéœéŸ³ï¼‰
    from pydub import AudioSegment
    from pydub.generators import Sine
    
    # å‰µå»º 30 ç§’çš„ç¤ºç¯„éŸ³é »
    sample_audio = AudioSegment.silent(duration=30000)  # 30ç§’éœéŸ³
    
    # æ·»åŠ ä¸€äº›éŸ³èª¿ä¾†æ¨¡æ“¬å°è©±
    tone1 = Sine(440).to_audio_segment(duration=2000)  # A4 éŸ³èª¿ 2ç§’
    tone2 = Sine(523).to_audio_segment(duration=2000)  # C5 éŸ³èª¿ 2ç§’
    
    # çµ„åˆéŸ³é »
    sample_audio = sample_audio[:5000] + tone1 + sample_audio[7000:15000] + tone2 + sample_audio[17000:]
    
    # ä¿å­˜ç¤ºç¯„æ–‡ä»¶
    sample_path = "input/sample_notebookllm.wav"
    os.makedirs("input", exist_ok=True)
    sample_audio.export(sample_path, format="wav")
    
    print(f"âœ… ç¤ºç¯„éŸ³é »å·²å‰µå»º: {sample_path}")
    return sample_path

def create_sample_transcript():
    """å‰µå»ºç¤ºç¯„è½‰éŒ„æ–‡æœ¬ï¼ˆç”¨æ–¼æ¸¬è©¦ç¿»è­¯åŠŸèƒ½ï¼‰"""
    sample_segments = [
        {
            'start': 0.0,
            'end': 5.0,
            'text': "Welcome to today's discussion about artificial intelligence and its transformative impact on modern society.",
            'words': [],
            'speaker': 'A',
            'is_question': False,
            'is_response': False,
            'is_transition': True
        },
        {
            'start': 5.5,
            'end': 12.0,
            'text': "What do you think are the most significant challenges we face with AI development in the coming years?",
            'words': [],
            'speaker': 'B',
            'is_question': True,
            'is_response': False,
            'is_transition': False
        },
        {
            'start': 12.5,
            'end': 20.0,
            'text': "Well, I believe the main concerns revolve around ethical considerations, job displacement, and ensuring AI systems remain beneficial to humanity.",
            'words': [],
            'speaker': 'A',
            'is_question': False,
            'is_response': True,
            'is_transition': False
        },
        {
            'start': 20.5,
            'end': 28.0,
            'text': "Speaking of ethics, how do we ensure AI systems are fair, transparent, and free from harmful biases?",
            'words': [],
            'speaker': 'B',
            'is_question': True,
            'is_response': False,
            'is_transition': True
        }
    ]
    
    return {
        'text': ' '.join([seg['text'] for seg in sample_segments]),
        'segments': sample_segments,
        'language': 'en'
    }

async def demo_translation_only():
    """ç¤ºç¯„ç´”ç¿»è­¯åŠŸèƒ½ï¼ˆä¸éœ€è¦éŸ³é »æ–‡ä»¶ï¼‰"""
    print("\nğŸ§ª ç¤ºç¯„ç¿»è­¯åŠŸèƒ½...")
    
    processor = AudioProcessor()
    
    # ä½¿ç”¨ç¤ºç¯„è½‰éŒ„æ–‡æœ¬
    transcription = create_sample_transcript()
    
    # å°è©±åˆ†æ
    dialogue_segments = processor.detect_speakers_and_dialogue(transcription['segments'])
    
    # ç¿»è­¯
    translated_segments = processor.translate_with_context(dialogue_segments)
    
    # é¡¯ç¤ºçµæœ
    print("\nğŸ“ ç¿»è­¯çµæœ:")
    print("=" * 60)
    
    for i, segment in enumerate(translated_segments, 1):
        print(f"\nç‰‡æ®µ {i} ({segment['speaker']}):")
        print(f"åŸæ–‡: {segment['original_text']}")
        print(f"è­¯æ–‡: {segment['translated_text']}")
        
        # é¡¯ç¤ºå°è©±ç‰¹å¾µ
        features = []
        if segment.get('is_question'):
            features.append("å•å¥")
        if segment.get('is_response'):
            features.append("å›æ‡‰")
        if segment.get('is_transition'):
            features.append("è½‰å ´")
        
        if features:
            print(f"ç‰¹å¾µ: {', '.join(features)}")
    
    return translated_segments

async def demo_full_process(input_path: str):
    """ç¤ºç¯„å®Œæ•´è™•ç†æµç¨‹"""
    print(f"\nğŸš€ é–‹å§‹å®Œæ•´è™•ç†æµç¨‹: {input_path}")
    
    processor = AudioProcessor()
    
    # å‰µå»ºè¼¸å‡ºç›®éŒ„
    output_dir = "output/demo_result"
    os.makedirs(output_dir, exist_ok=True)
    
    try:
        # å®Œæ•´è™•ç†
        result = await processor.process_audio_complete(input_path, output_dir)
        
        if result:
            print("\nğŸ‰ è™•ç†å®Œæˆï¼")
            print("=" * 50)
            print(f"åŸå§‹éŸ³é »: {result['original_audio']}")
            print(f"ä¸­æ–‡éŸ³é »: {result['chinese_audio']}")
            print(f"é€å­—ç¨¿: {result['transcript']}")
            print(f"ç‰‡æ®µæ•¸é‡: {result['segments_count']}")
            print(f"ç¸½æ™‚é•·: {result['total_duration']:.2f} ç§’")
            
            return result
        else:
            print("âŒ è™•ç†å¤±æ•—")
            return None
            
    except Exception as e:
        print(f"âŒ è™•ç†éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}")
        return None

def check_environment():
    """æª¢æŸ¥ç’°å¢ƒè¨­å®š"""
    print("ğŸ” æª¢æŸ¥ç’°å¢ƒè¨­å®š...")
    
    # æª¢æŸ¥ API é‡‘é‘°
    openai_key = os.getenv('OPENAI_API_KEY')
    gemini_key = os.getenv('GEMINI_API_KEY') or os.getenv('GOOGLE_API_KEY')
    
    print(f"OpenAI API: {'âœ… å·²è¨­å®š' if openai_key and openai_key != 'sk-your_openai_api_key_here' else 'âŒ æœªè¨­å®š'}")
    print(f"Gemini API: {'âœ… å·²è¨­å®š' if gemini_key and gemini_key != 'your_gemini_api_key_here' else 'âŒ æœªè¨­å®š'}")
    
    # æª¢æŸ¥ç›®éŒ„
    required_dirs = ['input', 'output', 'temp']
    for dir_name in required_dirs:
        if not os.path.exists(dir_name):
            os.makedirs(dir_name, exist_ok=True)
            print(f"ğŸ“ å·²å‰µå»ºç›®éŒ„: {dir_name}")
        else:
            print(f"ğŸ“ ç›®éŒ„å­˜åœ¨: {dir_name}")

async def main():
    """ä¸»ç¨‹å¼"""
    print("ğŸ™ï¸  NotebookLM ä¸­æ–‡ Podcast è™•ç†å™¨ - ç¤ºç¯„")
    print("=" * 60)
    
    # è¼‰å…¥ç’°å¢ƒè®Šæ•¸
    load_dotenv()
    
    # æª¢æŸ¥ç’°å¢ƒ
    check_environment()
    
    # æª¢æŸ¥å‘½ä»¤è¡Œåƒæ•¸
    if len(sys.argv) > 1:
        input_path = sys.argv[1]
        if not os.path.exists(input_path):
            print(f"âŒ æ‰¾ä¸åˆ°è¼¸å…¥æ–‡ä»¶: {input_path}")
            return
    else:
        print("\nğŸ’¡ æœªæä¾›è¼¸å…¥æ–‡ä»¶ï¼Œå°‡ä½¿ç”¨ç¤ºç¯„æ¨¡å¼")
        
        # è©¢å•ç”¨æˆ¶é¸æ“‡
        print("\nè«‹é¸æ“‡ç¤ºç¯„æ¨¡å¼:")
        print("1. ç´”ç¿»è­¯ç¤ºç¯„ï¼ˆä¸éœ€è¦éŸ³é »æ–‡ä»¶ï¼‰")
        print("2. å®Œæ•´æµç¨‹ç¤ºç¯„ï¼ˆä½¿ç”¨ç¤ºç¯„éŸ³é »ï¼‰")
        print("3. é€€å‡º")
        
        choice = input("\nè«‹è¼¸å…¥é¸æ“‡ (1-3): ").strip()
        
        if choice == "1":
            await demo_translation_only()
            return
        elif choice == "2":
            input_path = create_sample_audio()
        elif choice == "3":
            print("é€€å‡ºç¤ºç¯„")
            return
        else:
            print("âŒ ç„¡æ•ˆé¸æ“‡")
            return
    
    # åŸ·è¡Œå®Œæ•´è™•ç†æµç¨‹
    result = await demo_full_process(input_path)
    
    if result:
        print("\nğŸ’¡ æç¤º:")
        print("- æª¢æŸ¥è¼¸å‡ºç›®éŒ„ä¸­çš„çµæœæ–‡ä»¶")
        print("- å¦‚æœç¿»è­¯å“è³ªä¸ç†æƒ³ï¼Œè«‹æª¢æŸ¥ API é‡‘é‘°è¨­å®š")
        print("- å¯ä»¥èª¿æ•´ .env æ–‡ä»¶ä¸­çš„æ¨¡å‹å’Œè²éŸ³è¨­å®š")

if __name__ == "__main__":
    asyncio.run(main()) 