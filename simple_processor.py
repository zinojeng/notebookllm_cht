#!/usr/bin/env python3
"""
NotebookLM ä¸­æ–‡ Podcast è™•ç†å™¨ - ç°¡åŒ–ç‰ˆ
å°ˆæ³¨æ–¼ç¿»è­¯åŠŸèƒ½ï¼Œå±•ç¤º AI ç¿»è­¯èƒ½åŠ›

ä½¿ç”¨æ–¹æ³•:
python simple_processor.py
"""

import os
import asyncio
import edge_tts
from deep_translator import GoogleTranslator
import json
from typing import List, Dict
from datetime import datetime
from dotenv import load_dotenv

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸
load_dotenv()

# API æ”¯æ´
try:
    import openai
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False

try:
    import google.generativeai as genai
    GEMINI_AVAILABLE = True
except ImportError:
    GEMINI_AVAILABLE = False

class SimpleProcessor:
    def __init__(self):
        """åˆå§‹åŒ–ç°¡åŒ–è™•ç†å™¨"""
        # è¼‰å…¥ç’°å¢ƒè®Šæ•¸
        self.openai_api_key = os.getenv('OPENAI_API_KEY')
        self.gemini_api_key = os.getenv('GEMINI_API_KEY') or os.getenv('GOOGLE_API_KEY')
        
        # è¨­å®šç¿»è­¯æä¾›å•†
        self.translation_provider = os.getenv('TRANSLATION_PROVIDER', 'google').lower()
        
        # åˆå§‹åŒ–ç¿»è­¯å™¨
        self._init_translators()
        
        # ä¸­æ–‡èªéŸ³è¨­å®š
        self.chinese_voices = {
            'female': os.getenv('EDGE_TTS_VOICE_FEMALE', 'zh-TW-HsiaoChenNeural'),
            'male': os.getenv('EDGE_TTS_VOICE_MALE', 'zh-TW-YunJheNeural')
        }
        
        print(f"ğŸ”§ ç°¡åŒ–è™•ç†å™¨åˆå§‹åŒ–å®Œæˆ")
        print(f"   ç¿»è­¯æä¾›å•†: {self.translation_provider}")
        print(f"   å¥³æ€§è²éŸ³: {self.chinese_voices['female']}")
        print(f"   ç”·æ€§è²éŸ³: {self.chinese_voices['male']}")
    
    def _init_translators(self):
        """åˆå§‹åŒ–ç¿»è­¯å™¨"""
        self.translator = GoogleTranslator(source='en', target='zh-TW')
        
        # å¾ç’°å¢ƒè®Šæ•¸ç²å–æ¨¡å‹åç¨±
        self.openai_model = os.getenv('OPENAI_MODEL', 'o1-mini')
        self.gemini_model_name = os.getenv('GEMINI_MODEL', 'gemini-2.0-flash-exp')
        
        # åˆå§‹åŒ– OpenAI
        if self.openai_api_key and OPENAI_AVAILABLE:
            self.openai_client = openai.OpenAI(api_key=self.openai_api_key)
            print(f"âœ… OpenAI å®¢æˆ¶ç«¯åˆå§‹åŒ–å®Œæˆ (æ¨¡å‹: {self.openai_model})")
        else:
            self.openai_client = None
            if self.translation_provider == 'openai':
                print("âš ï¸  OpenAI API é‡‘é‘°æœªè¨­å®šï¼Œå°‡ä½¿ç”¨ Google ç¿»è­¯")
                self.translation_provider = 'google'
        
        # åˆå§‹åŒ– Gemini
        if self.gemini_api_key and GEMINI_AVAILABLE:
            genai.configure(api_key=self.gemini_api_key)
            self.gemini_model = genai.GenerativeModel(self.gemini_model_name)
            print(f"âœ… Gemini å®¢æˆ¶ç«¯åˆå§‹åŒ–å®Œæˆ (æ¨¡å‹: {self.gemini_model_name})")
        else:
            self.gemini_model = None
            if self.translation_provider == 'gemini':
                print("âš ï¸  Gemini API é‡‘é‘°æœªè¨­å®šï¼Œå°‡ä½¿ç”¨ Google ç¿»è­¯")
                self.translation_provider = 'google'
    
    def translate_with_ai(self, text: str, context: Dict = None) -> str:
        """ä½¿ç”¨ AI æ¨¡å‹é€²è¡Œæ™ºèƒ½ç¿»è­¯"""
        if self.translation_provider == 'openai' and self.openai_client:
            return self._translate_with_openai(text, context)
        elif self.translation_provider == 'gemini' and self.gemini_model:
            return self._translate_with_gemini(text, context)
        else:
            # å›é€€åˆ° Google ç¿»è­¯
            return self.translator.translate(text)
    
    def _translate_with_openai(self, text: str, context: Dict = None) -> str:
        """ä½¿ç”¨ OpenAI o1-mini é€²è¡Œç¿»è­¯"""
        try:
            # æ§‹å»ºæç¤ºè©
            system_prompt = """ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„è‹±æ–‡åˆ°ç¹é«”ä¸­æ–‡ç¿»è­¯å°ˆå®¶ï¼Œå°ˆé–€è™•ç† Podcast å°è©±å…§å®¹ã€‚

ç¿»è­¯è¦æ±‚ï¼š
1. ä¿æŒå°è©±çš„è‡ªç„¶æ€§å’Œå£èªåŒ–ç‰¹è‰²
2. æ ¹æ“šèªªè©±è€…è§’è‰²èª¿æ•´èªæ°£ï¼ˆä¸»æŒäºº vs å˜‰è³“ï¼‰
3. ä¿ç•™å°è©±ä¸­çš„èªæ°£è©å’Œè½‰æŠ˜è©
4. ä½¿ç”¨å°ç£ç¹é«”ä¸­æ–‡çš„è¡¨é”ç¿’æ…£
5. å°æ–¼å°ˆæ¥­è¡“èªï¼Œæä¾›è‡ªç„¶çš„ä¸­æ–‡è¡¨é”

è«‹ç›´æ¥è¿”å›ç¿»è­¯çµæœï¼Œä¸è¦æ·»åŠ ä»»ä½•è§£é‡‹ã€‚"""

            user_prompt = f"è«‹å°‡ä»¥ä¸‹è‹±æ–‡å°è©±ç¿»è­¯æˆè‡ªç„¶çš„ç¹é«”ä¸­æ–‡ï¼š\n\n{text}"
            
            # å¦‚æœæœ‰ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œæ·»åŠ åˆ°æç¤ºä¸­
            if context:
                if context.get('is_question'):
                    user_prompt += "\n\næ³¨æ„ï¼šé€™æ˜¯ä¸€å€‹å•å¥ï¼Œè«‹ç¢ºä¿ç¿»è­¯å¾Œä¿æŒç–‘å•èªæ°£ã€‚"
                elif context.get('is_response'):
                    user_prompt += "\n\næ³¨æ„ï¼šé€™æ˜¯å°å‰é¢å•é¡Œçš„å›æ‡‰ï¼Œè«‹ä½¿ç”¨è‡ªç„¶çš„å›ç­”èªæ°£ã€‚"
                elif context.get('is_transition'):
                    user_prompt += "\n\næ³¨æ„ï¼šé€™æ˜¯è©±é¡Œè½‰æ›ï¼Œè«‹ä½¿ç”¨é©ç•¶çš„è½‰å ´è¡¨é”ã€‚"
            
            response = self.openai_client.chat.completions.create(
                model=self.openai_model,
                messages=[
                    {"role": "user", "content": f"{system_prompt}\n\n{user_prompt}"}
                ],
                max_completion_tokens=1000,
                temperature=0.3
            )
            
            return response.choices[0].message.content.strip()
            
        except Exception as e:
            print(f"âš ï¸  OpenAI ç¿»è­¯å¤±æ•—ï¼Œä½¿ç”¨å‚™ç”¨ç¿»è­¯: {e}")
            return self.translator.translate(text)
    
    def _translate_with_gemini(self, text: str, context: Dict = None) -> str:
        """ä½¿ç”¨ Gemini 2.0 Flash Preview é€²è¡Œç¿»è­¯"""
        try:
            # æ§‹å»ºæç¤ºè©
            prompt = f"""ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„è‹±æ–‡åˆ°ç¹é«”ä¸­æ–‡ç¿»è­¯å°ˆå®¶ï¼Œå°ˆé–€è™•ç† Podcast å°è©±å…§å®¹ã€‚

ç¿»è­¯è¦æ±‚ï¼š
1. ä¿æŒå°è©±çš„è‡ªç„¶æ€§å’Œå£èªåŒ–ç‰¹è‰²
2. æ ¹æ“šèªªè©±è€…è§’è‰²èª¿æ•´èªæ°£
3. ä¿ç•™å°è©±ä¸­çš„èªæ°£è©å’Œè½‰æŠ˜è©
4. ä½¿ç”¨å°ç£ç¹é«”ä¸­æ–‡çš„è¡¨é”ç¿’æ…£
5. å°æ–¼å°ˆæ¥­è¡“èªï¼Œæä¾›è‡ªç„¶çš„ä¸­æ–‡è¡¨é”

è«‹å°‡ä»¥ä¸‹è‹±æ–‡å°è©±ç¿»è­¯æˆè‡ªç„¶çš„ç¹é«”ä¸­æ–‡ï¼š

{text}

è«‹ç›´æ¥è¿”å›ç¿»è­¯çµæœï¼Œä¸è¦æ·»åŠ ä»»ä½•è§£é‡‹ã€‚"""

            # å¦‚æœæœ‰ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œæ·»åŠ åˆ°æç¤ºä¸­
            if context:
                if context.get('is_question'):
                    prompt += "\n\næ³¨æ„ï¼šé€™æ˜¯ä¸€å€‹å•å¥ï¼Œè«‹ç¢ºä¿ç¿»è­¯å¾Œä¿æŒç–‘å•èªæ°£ã€‚"
                elif context.get('is_response'):
                    prompt += "\n\næ³¨æ„ï¼šé€™æ˜¯å°å‰é¢å•é¡Œçš„å›æ‡‰ï¼Œè«‹ä½¿ç”¨è‡ªç„¶çš„å›ç­”èªæ°£ã€‚"
                elif context.get('is_transition'):
                    prompt += "\n\næ³¨æ„ï¼šé€™æ˜¯è©±é¡Œè½‰æ›ï¼Œè«‹ä½¿ç”¨é©ç•¶çš„è½‰å ´è¡¨é”ã€‚"
            
            response = self.gemini_model.generate_content(prompt)
            return response.text.strip()
            
        except Exception as e:
            print(f"âš ï¸  Gemini ç¿»è­¯å¤±æ•—ï¼Œä½¿ç”¨å‚™ç”¨ç¿»è­¯: {e}")
            return self.translator.translate(text)
    
    def detect_speakers_and_dialogue(self, segments: List[Dict]) -> List[Dict]:
        """æª¢æ¸¬å°è©±æ¨¡å¼ä¸¦æ¨™è¨˜èªªè©±è€…"""
        dialogue_segments = []
        
        for i, segment in enumerate(segments):
            text = segment['text'].strip()
            
            # æª¢æ¸¬å°è©±ç‰¹å¾µ
            is_question = text.endswith('?') or any(word in text.lower() for word in ['what', 'how', 'why', 'when', 'where', 'who'])
            is_response = any(word in text.lower() for word in ['well', 'actually', 'so', 'yeah', 'right', 'exactly'])
            is_transition = any(phrase in text.lower() for phrase in ['speaking of', 'by the way', 'another thing', 'also'])
            
            # ç°¡å–®çš„èªªè©±è€…æª¢æ¸¬ï¼ˆåŸºæ–¼å°è©±æ¨¡å¼ï¼‰
            if i == 0:
                speaker = 'A'
            elif is_question and dialogue_segments and dialogue_segments[-1]['speaker'] == 'A':
                speaker = 'B'
            elif is_response and dialogue_segments and dialogue_segments[-1]['speaker'] == 'B':
                speaker = 'A'
            else:
                # ä¿æŒå‰ä¸€å€‹èªªè©±è€…ï¼Œé™¤éæœ‰æ˜é¡¯çš„è½‰æ›
                speaker = dialogue_segments[-1]['speaker'] if dialogue_segments else 'A'
                if len(text) > 100 and i > 0:  # é•·å¥å­å¯èƒ½æ˜¯èªªè©±è€…è½‰æ›
                    speaker = 'B' if speaker == 'A' else 'A'
            
            dialogue_segments.append({
                **segment,
                'speaker': speaker,
                'is_question': is_question,
                'is_response': is_response,
                'is_transition': is_transition
            })
        
        print(f"âœ… å°è©±åˆ†æå®Œæˆï¼Œæª¢æ¸¬åˆ° {len(set(seg['speaker'] for seg in dialogue_segments))} å€‹èªªè©±è€…")
        return dialogue_segments
    
    def translate_with_context(self, segments: List[Dict]) -> List[Dict]:
        """ç¿»è­¯æ–‡æœ¬ï¼Œä¿æŒå°è©±çš„è‡ªç„¶æ€§"""
        translated_segments = []
        
        print("ğŸŒ é–‹å§‹ç¿»è­¯...")
        print(f"   ä½¿ç”¨ç¿»è­¯æä¾›å•†: {self.translation_provider}")
        
        for i, segment in enumerate(segments):
            try:
                original_text = segment['text']
                
                # æº–å‚™ä¸Šä¸‹æ–‡ä¿¡æ¯
                context = {
                    'is_question': segment.get('is_question', False),
                    'is_response': segment.get('is_response', False),
                    'is_transition': segment.get('is_transition', False),
                    'speaker': segment.get('speaker', 'A')
                }
                
                # ä½¿ç”¨ AI ç¿»è­¯ï¼ˆå¦‚æœå¯ç”¨ï¼‰æˆ–å›é€€åˆ° Google ç¿»è­¯
                translated = self.translate_with_ai(original_text, context)
                
                # å¾Œè™•ç†ï¼šèª¿æ•´ä¸­æ–‡è¡¨é”ä½¿å…¶æ›´è‡ªç„¶
                translated = self.enhance_chinese_dialogue(translated, segment)
                
                translated_segments.append({
                    **segment,
                    'original_text': original_text,
                    'translated_text': translated
                })
                
                print(f"   {i+1}/{len(segments)} - ç¿»è­¯å®Œæˆ")
                
            except Exception as e:
                print(f"âŒ ç¿»è­¯ç¬¬ {i+1} æ®µå¤±æ•—: {e}")
                translated_segments.append({
                    **segment,
                    'original_text': segment['text'],
                    'translated_text': segment['text']  # ä¿ç•™åŸæ–‡
                })
        
        print("âœ… ç¿»è­¯å®Œæˆ")
        return translated_segments
    
    def enhance_chinese_dialogue(self, translated_text: str, segment: Dict) -> str:
        """å¢å¼·ä¸­æ–‡å°è©±çš„è‡ªç„¶æ€§"""
        text = translated_text
        
        # æ ¹æ“šå°è©±é¡å‹èª¿æ•´è¡¨é”
        if segment.get('is_question'):
            # å•å¥èª¿æ•´
            if not text.endswith('ï¼Ÿ') and not text.endswith('?'):
                text += 'ï¼Ÿ'
            # æ·»åŠ è‡ªç„¶çš„å•å¥é–‹é ­
            question_starters = ['é‚£éº¼', 'æ‰€ä»¥', 'é‚£', 'å—¯']
            if not any(text.startswith(starter) for starter in question_starters):
                if 'ä»€éº¼' in text or 'æ€éº¼' in text:
                    text = 'é‚£' + text
        
        elif segment.get('is_response'):
            # å›æ‡‰èª¿æ•´
            response_starters = ['å—¯', 'å°', 'æ˜¯çš„', 'æ²’éŒ¯', 'ç¢ºå¯¦']
            if not any(text.startswith(starter) for starter in response_starters):
                text = 'å—¯ï¼Œ' + text
        
        elif segment.get('is_transition'):
            # è½‰å ´èª¿æ•´
            transition_words = ['èªªåˆ°é€™å€‹', 'é †ä¾¿èªªä¸€ä¸‹', 'å¦å¤–', 'é‚„æœ‰']
            if not any(phrase in text for phrase in transition_words):
                text = 'èªªåˆ°é€™å€‹ï¼Œ' + text
        
        # æ·»åŠ è‡ªç„¶çš„èªæ°£è©
        if len(text) > 50 and 'ï¼Œ' in text:
            # åœ¨é•·å¥ä¸­é–“æ·»åŠ èªæ°£è©
            parts = text.split('ï¼Œ')
            if len(parts) > 1:
                parts[0] += 'å‘¢'
                text = 'ï¼Œ'.join(parts)
        
        return text
    
    async def generate_chinese_audio_simple(self, segments: List[Dict], output_dir: str) -> str:
        """ç”Ÿæˆä¸­æ–‡èªéŸ³ï¼ˆç°¡åŒ–ç‰ˆï¼‰"""
        os.makedirs(output_dir, exist_ok=True)
        
        print("ğŸ¤ é–‹å§‹ç”Ÿæˆä¸­æ–‡èªéŸ³...")
        
        # åˆä½µæ‰€æœ‰æ–‡æœ¬
        full_text = ""
        for segment in segments:
            speaker_voice = self.chinese_voices['female'] if segment['speaker'] == 'A' else self.chinese_voices['male']
            text = segment['translated_text']
            
            # æ·»åŠ èªªè©±è€…æ¨™è¨˜å’Œåœé “
            if segment['speaker'] == 'A':
                full_text += f"[å¥³è²] {text} [åœé “] "
            else:
                full_text += f"[ç”·è²] {text} [åœé “] "
        
        # ç”Ÿæˆå–®å€‹éŸ³é »æ–‡ä»¶
        output_file = os.path.join(output_dir, "chinese_podcast_simple.wav")
        
        # ä½¿ç”¨å¥³è²ä½œç‚ºä¸»è¦è²éŸ³
        communicate = edge_tts.Communicate(full_text, self.chinese_voices['female'])
        await communicate.save(output_file)
        
        print(f"âœ… ä¸­æ–‡èªéŸ³ç”Ÿæˆå®Œæˆ: {output_file}")
        return output_file
    
    def save_transcript(self, segments: List[Dict], output_path: str):
        """ä¿å­˜é€å­—ç¨¿"""
        try:
            transcript_data = {
                'timestamp': datetime.now().isoformat(),
                'total_segments': len(segments),
                'segments': []
            }
            
            for segment in segments:
                transcript_data['segments'].append({
                    'start_time': f"{segment.get('start', 0):.2f}s",
                    'end_time': f"{segment.get('end', 0):.2f}s",
                    'speaker': segment['speaker'],
                    'original_text': segment['original_text'],
                    'translated_text': segment['translated_text'],
                    'dialogue_type': {
                        'is_question': segment.get('is_question', False),
                        'is_response': segment.get('is_response', False),
                        'is_transition': segment.get('is_transition', False)
                    }
                })
            
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(transcript_data, f, ensure_ascii=False, indent=2)
            
            print(f"âœ… é€å­—ç¨¿å·²ä¿å­˜: {output_path}")
            
        except Exception as e:
            print(f"âŒ ä¿å­˜é€å­—ç¨¿å¤±æ•—: {e}")

def create_sample_transcript():
    """å‰µå»ºç¤ºç¯„è½‰éŒ„æ–‡æœ¬"""
    sample_segments = [
        {
            'start': 0.0,
            'end': 5.0,
            'text': "Welcome to today's discussion about artificial intelligence and its transformative impact on modern society.",
            'words': []
        },
        {
            'start': 5.5,
            'end': 12.0,
            'text': "What do you think are the most significant challenges we face with AI development in the coming years?",
            'words': []
        },
        {
            'start': 12.5,
            'end': 20.0,
            'text': "Well, I believe the main concerns revolve around ethical considerations, job displacement, and ensuring AI systems remain beneficial to humanity.",
            'words': []
        },
        {
            'start': 20.5,
            'end': 28.0,
            'text': "Speaking of ethics, how do we ensure AI systems are fair, transparent, and free from harmful biases?",
            'words': []
        },
        {
            'start': 28.5,
            'end': 35.0,
            'text': "That's an excellent question. We need robust governance frameworks and diverse teams working on AI development.",
            'words': []
        }
    ]
    
    return {
        'text': ' '.join([seg['text'] for seg in sample_segments]),
        'segments': sample_segments,
        'language': 'en'
    }

async def main():
    """ä¸»ç¨‹å¼"""
    print("ğŸ™ï¸  NotebookLM ä¸­æ–‡ Podcast è™•ç†å™¨ - ç°¡åŒ–ç‰ˆç¤ºç¯„")
    print("=" * 60)
    
    # è¼‰å…¥ç’°å¢ƒè®Šæ•¸
    load_dotenv()
    
    # åˆå§‹åŒ–è™•ç†å™¨
    processor = SimpleProcessor()
    
    # ä½¿ç”¨ç¤ºç¯„è½‰éŒ„æ–‡æœ¬
    print("\nğŸ“ ä½¿ç”¨ç¤ºç¯„è½‰éŒ„æ–‡æœ¬...")
    transcription = create_sample_transcript()
    
    # å°è©±åˆ†æ
    print("\nğŸ” åˆ†æå°è©±æ¨¡å¼...")
    dialogue_segments = processor.detect_speakers_and_dialogue(transcription['segments'])
    
    # ç¿»è­¯
    print("\nğŸŒ é–‹å§‹ç¿»è­¯...")
    translated_segments = processor.translate_with_context(dialogue_segments)
    
    # é¡¯ç¤ºçµæœ
    print("\nğŸ“ ç¿»è­¯çµæœ:")
    print("=" * 60)
    
    for i, segment in enumerate(translated_segments, 1):
        print(f"\nç‰‡æ®µ {i} ({segment['speaker']}):")
        print(f"åŸæ–‡: {segment['original_text']}")
        print(f"è­¯æ–‡: {segment['translated_text']}")
        
        # é¡¯ç¤ºå°è©±ç‰¹å¾µ
        features = []
        if segment.get('is_question'):
            features.append("å•å¥")
        if segment.get('is_response'):
            features.append("å›æ‡‰")
        if segment.get('is_transition'):
            features.append("è½‰å ´")
        
        if features:
            print(f"ç‰¹å¾µ: {', '.join(features)}")
    
    # å‰µå»ºè¼¸å‡ºç›®éŒ„
    output_dir = "output/simple_demo"
    os.makedirs(output_dir, exist_ok=True)
    
    # ä¿å­˜é€å­—ç¨¿
    transcript_path = os.path.join(output_dir, "transcript.json")
    processor.save_transcript(translated_segments, transcript_path)
    
    # ç”ŸæˆèªéŸ³ï¼ˆå¯é¸ï¼‰
    try:
        print("\nğŸ¤ ç”Ÿæˆä¸­æ–‡èªéŸ³...")
        audio_path = await processor.generate_chinese_audio_simple(translated_segments, output_dir)
        print(f"âœ… èªéŸ³æ–‡ä»¶å·²ç”Ÿæˆ: {audio_path}")
    except Exception as e:
        print(f"âš ï¸  èªéŸ³ç”Ÿæˆå¤±æ•—: {e}")
    
    print("\nğŸ‰ ç¤ºç¯„å®Œæˆï¼")
    print(f"ğŸ“ è¼¸å‡ºç›®éŒ„: {output_dir}")
    print("\nğŸ’¡ æç¤º:")
    print("- æª¢æŸ¥ output/simple_demo/ ç›®éŒ„ä¸­çš„çµæœæ–‡ä»¶")
    print("- å¦‚æœç¿»è­¯å“è³ªä¸ç†æƒ³ï¼Œè«‹æª¢æŸ¥ API é‡‘é‘°è¨­å®š")
    print("- å¯ä»¥èª¿æ•´ .env æ–‡ä»¶ä¸­çš„æ¨¡å‹è¨­å®š")

if __name__ == "__main__":
    asyncio.run(main()) 