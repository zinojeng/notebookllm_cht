#!/usr/bin/env python3
"""
NotebookLM è‹±æ–‡éŸ³é »è½‰ä¸­æ–‡ Podcast è™•ç†å™¨
å°‡è‹±æ–‡å°è©±éŸ³é »è½‰æ›ç‚ºè‡ªç„¶çš„ä¸­æ–‡å°è©±éŸ³é »
"""

import asyncio
import argparse
import os
import sys
from pathlib import Path
from audio_processor import AudioProcessor

def validate_input_file(file_path: str) -> bool:
    """é©—è­‰è¼¸å…¥æ–‡ä»¶"""
    if not os.path.exists(file_path):
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        return False
    
    if not file_path.lower().endswith('.wav'):
        print(f"âŒ åƒ…æ”¯æ´ .wav æ ¼å¼æ–‡ä»¶")
        return False
    
    return True

async def main():
    parser = argparse.ArgumentParser(
        description="å°‡ NotebookLM è‹±æ–‡éŸ³é »æ¦‚è¦½è½‰æ›ç‚ºä¸­æ–‡ Podcast",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¯„ä¾‹:
  python main.py input.wav                    # è™•ç† input.wavï¼Œè¼¸å‡ºåˆ° output/ ç›®éŒ„
  python main.py input.wav -o my_output/     # æŒ‡å®šè¼¸å‡ºç›®éŒ„
  python main.py input.wav --preview         # åƒ…ç”Ÿæˆé€å­—ç¨¿é è¦½
  
è™•ç†æµç¨‹:
  1. ğŸ¯ èªéŸ³è­˜åˆ¥ (Whisper)
  2. ğŸ‘¥ å°è©±åˆ†æèˆ‡èªªè©±è€…æª¢æ¸¬
  3. ğŸŒ è‹±æ–‡è½‰ä¸­æ–‡ç¿»è­¯
  4. ğŸ¤ ä¸­æ–‡èªéŸ³åˆæˆ (Edge TTS)
  5. ğŸµ éŸ³é »åˆä½µèˆ‡å„ªåŒ–
        """
    )
    
    parser.add_argument(
        'input_file',
        help='è¼¸å…¥çš„ .wav éŸ³é »æ–‡ä»¶è·¯å¾‘'
    )
    
    parser.add_argument(
        '-o', '--output',
        default='output',
        help='è¼¸å‡ºç›®éŒ„ (é è¨­: output/)'
    )
    
    parser.add_argument(
        '--preview',
        action='store_true',
        help='åƒ…ç”Ÿæˆé€å­—ç¨¿é è¦½ï¼Œä¸ç”ŸæˆéŸ³é »'
    )
    
    parser.add_argument(
        '--voice-female',
        default='zh-TW-HsiaoChenNeural',
        help='å¥³æ€§è²éŸ³ (é è¨­: zh-TW-HsiaoChenNeural)'
    )
    
    parser.add_argument(
        '--voice-male',
        default='zh-TW-YunJheNeural',
        help='ç”·æ€§è²éŸ³ (é è¨­: zh-TW-YunJheNeural)'
    )
    
    args = parser.parse_args()
    
    # é©—è­‰è¼¸å…¥æ–‡ä»¶
    if not validate_input_file(args.input_file):
        sys.exit(1)
    
    # å»ºç«‹è¼¸å‡ºç›®éŒ„
    output_dir = Path(args.output)
    output_dir.mkdir(parents=True, exist_ok=True)
    
    print("ğŸ™ï¸  NotebookLM è‹±æ–‡éŸ³é »è½‰ä¸­æ–‡ Podcast è™•ç†å™¨")
    print("=" * 50)
    print(f"ğŸ“ è¼¸å…¥æ–‡ä»¶: {args.input_file}")
    print(f"ğŸ“ è¼¸å‡ºç›®éŒ„: {output_dir}")
    print(f"ğŸ¤ å¥³æ€§è²éŸ³: {args.voice_female}")
    print(f"ğŸ¤ ç”·æ€§è²éŸ³: {args.voice_male}")
    print("=" * 50)
    
    try:
        # åˆå§‹åŒ–è™•ç†å™¨
        processor = AudioProcessor()
        
        # è‡ªå®šç¾©è²éŸ³è¨­å®š
        processor.chinese_voices['female'] = args.voice_female
        processor.chinese_voices['male'] = args.voice_male
        
        if args.preview:
            # åƒ…é è¦½æ¨¡å¼
            print("ğŸ“‹ é è¦½æ¨¡å¼ï¼šåƒ…ç”Ÿæˆé€å­—ç¨¿...")
            
            # èªéŸ³è­˜åˆ¥
            transcription = processor.transcribe_with_timestamps(args.input_file)
            if not transcription:
                print("âŒ èªéŸ³è­˜åˆ¥å¤±æ•—")
                sys.exit(1)
            
            # å°è©±åˆ†æ
            dialogue_segments = processor.detect_speakers_and_dialogue(transcription['segments'])
            
            # ç¿»è­¯
            translated_segments = processor.translate_with_context(dialogue_segments)
            
            # ä¿å­˜é€å­—ç¨¿
            transcript_path = output_dir / "transcript_preview.json"
            processor.save_transcript(translated_segments, str(transcript_path))
            
            # é¡¯ç¤ºé è¦½
            print("\nğŸ“‹ é€å­—ç¨¿é è¦½:")
            print("-" * 40)
            for i, segment in enumerate(translated_segments[:5]):  # é¡¯ç¤ºå‰5æ®µ
                print(f"[{segment['start']:.1f}s-{segment['end']:.1f}s] èªªè©±è€…{segment['speaker']}:")
                print(f"  è‹±æ–‡: {segment['original_text']}")
                print(f"  ä¸­æ–‡: {segment['translated_text']}")
                print()
            
            if len(translated_segments) > 5:
                print(f"... é‚„æœ‰ {len(translated_segments) - 5} æ®µå…§å®¹")
            
            print(f"âœ… å®Œæ•´é€å­—ç¨¿å·²ä¿å­˜è‡³: {transcript_path}")
            
        else:
            # å®Œæ•´è™•ç†æ¨¡å¼
            result = await processor.process_audio_complete(
                args.input_file,
                str(output_dir)
            )
            
            if result:
                print("\nğŸ‰ è™•ç†å®Œæˆï¼")
                print("=" * 50)
                print(f"ğŸ“„ é€å­—ç¨¿: {result['transcript']}")
                print(f"ğŸµ ä¸­æ–‡éŸ³é »: {result['chinese_audio']}")
                print(f"ğŸ“Š ç‰‡æ®µæ•¸é‡: {result['segments_count']}")
                print(f"â±ï¸  ç¸½æ™‚é•·: {result['total_duration']:.2f} ç§’")
                print("\nğŸ§ æ‚¨ç¾åœ¨å¯ä»¥æ’­æ”¾ç”Ÿæˆçš„ä¸­æ–‡ Podcast äº†ï¼")
            else:
                print("âŒ è™•ç†å¤±æ•—")
                sys.exit(1)
    
    except KeyboardInterrupt:
        print("\nâš ï¸  è™•ç†è¢«ç”¨æˆ¶ä¸­æ–·")
        sys.exit(1)
    except Exception as e:
        print(f"âŒ è™•ç†éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}")
        sys.exit(1)

if __name__ == "__main__":
    asyncio.run(main()) 